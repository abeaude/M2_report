{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer trajectory with STREAM\n",
    "\n",
    "This notebook will guide you in the analysis of a single cell dataset to obtain a trajectory with the framework `stream`. \n",
    "All functions starting by `st.` like `st.read` are function from STREAM, some other functions like : `prep_data_dynverse` were created to ease the wrapping of STREAM results in R through the dynverse framework. If you are not running this notebook as part of the trajecotry pipeline, the execution of this functions are optionnal. \n",
    "\n",
    "To easily navigate through the notebook, you can find here some useful keyboard shortcuts : \n",
    " - Ctrl + Enter : Execute the cell\n",
    " - Maj + Enter : Execute cell and select the one below\n",
    " - Alt +Enter : Execute cell and insert a cell below\n",
    " - Esc : Command mode\n",
    " - Enter : Edition mode\n",
    " \n",
    "Some useful command in Command mode : \n",
    "  - A : Insert a cell above\n",
    "  - B : insert a cell below\n",
    "  \n",
    "Some useful commands in Edition mode : \n",
    " - Ctrl + / : Comment\n",
    " \n",
    "To access the help of a function just add `?` at the end of the function name and execute the line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stream as st\n",
    "import pandas as pd\n",
    "import matplotlib as mplt\n",
    "mplt.rcParams.update({'figure.max_open_warning': 0})\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_dynverse(adata,root, filename = 'stream_to_dynverse', path = None):\n",
    "    \n",
    "    filename+=\"_\"+root\n",
    "    if(path is None):\n",
    "        path = adata.uns['workdir']\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    \n",
    "    flat_tree = adata.uns['flat_tree']\n",
    " \n",
    "    # Raw count\n",
    "#     adata.raw.X.tofile(filename+'_raw_counts.csv',sep=',')\n",
    "    pd.DataFrame(data=adata.raw.X, index=adata.raw.obs_names, columns=adata.raw.var_names).to_csv(filename+'_raw_counts.csv',index = True, index_label = 'cell_id', sep = \",\", doublequote = False)\n",
    "    # Log count \n",
    "#     adata.X.tofile(filename+'_counts.csv',sep=',')\n",
    "    pd.DataFrame(data=adata.X, index=adata.obs_names, columns=adata.var_names).to_csv(filename+'_counts.csv',index = True, index_label = 'cell_id', sep = \",\", doublequote = False)\n",
    "\n",
    "    # Progression\n",
    "    data = pd.DataFrame({'cell_id':adata.obs_names, 'edge_id':adata.obs['branch_id'],\n",
    "                 'edge_id_alias':adata.obs['branch_id_alias'], 'branch_lam':adata.obs['branch_lam']})\n",
    "\n",
    "    branch_len = list()\n",
    "    for i in data['edge_id']:\n",
    "        branch_len.append(flat_tree[i[0]][i[1]]['len'])\n",
    "\n",
    "    data['branch_len'] = branch_len\n",
    "\n",
    "    data['percentage'] = data.apply(lambda row: row.branch_lam / row.branch_len, axis=1)\n",
    "\n",
    "    from_to = data['edge_id_alias'].astype(str).str.replace('[\\(\\) ]','').str.split(',',expand= True)\n",
    "    data['from'] = from_to[0]\n",
    "    data['to'] = from_to[1]\n",
    "    \n",
    "    flat_tree = adata.uns['flat_tree']\n",
    "    # Millestone network\n",
    "    node_label = nx.get_node_attributes(flat_tree,'label')\n",
    "    node_index = {v: k for k, v in node_label.items()}\n",
    "    node_index\n",
    "\n",
    "    length , directed , from_ , to_ = list(),list(),list(),list()\n",
    "    for edge in data['edge_id_alias'].unique():\n",
    "        length.append(flat_tree[node_index[edge[0]]][node_index[edge[1]]]['len'])\n",
    "        directed.append(False)\n",
    "        from_.append(edge[0])\n",
    "        to_.append(edge[1])\n",
    "\n",
    "    millestone_network = pd.DataFrame({'from':from_, 'to':to_, 'length':length, 'directed':directed})\n",
    "    millestone_network.to_csv(filename+'_millestone_network.csv',index = False, sep = \",\", doublequote = False)\n",
    "    \n",
    "    # saving progression\n",
    "    data = data.drop(columns=['edge_id', 'edge_id_alias', 'branch_lam', 'branch_len'])\n",
    "    data.to_csv(filename+'_progression.csv',index = False, sep = \",\", doublequote = False)\n",
    "    \n",
    "    # Dimension reduction\n",
    "    pd.DataFrame(adata.obsm['X_dr'],index=adata.obs_names).to_csv(filename+'_dim_red.csv',index = True, index_label = 'cell_id', sep = \",\", doublequote = False)\n",
    "    # Grouping \n",
    "    adata.obs.label.to_csv(filename+'_grouping.csv',index = True, index_label = 'cell_id', sep = \",\", doublequote = False)\n",
    "    \n",
    "    os.chdir(cwd)\n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STREAM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_figure_params(dpi=80,style='white',figsize=[5.4,4.8],\n",
    "                     rc={'image.cmap': 'viridis'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "First we need to create an adata object by calling `st.read` with the following paramaters : \n",
    " - file_name : name of the tsv file containing the count\n",
    " - workdir : folder where to save all the output (created automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=st.read(file_name='../data_for_trajectories.tsv',workdir='./stream_result')\n",
    "adata.raw = adata\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add metadata in order to identify the cells (like different subtypes of cells). \n",
    " - `st.add_cell_labels(adata,file_name='./cell_label_subset.tsv.gz')`\n",
    " - `st.add_cell_colors(adata,file_name='./cell_label_color_subset.tsv.gz')`\n",
    "\n",
    "If you do not have this information you need to simply run : \n",
    " - `st.add_cell_labels(adata)`, which will identify all the cells as unknown\n",
    " - `st.add_cell_colors(adata)`, which will add random colors to the cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.add_cell_labels(adata,file_name='../data_for_trajectories_cell_identities.tsv')\n",
    "st.add_cell_colors(adata,file_name='../data_for_trajectories_cell_colors.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "When dealing with raw count you to have preprocess your data with the following steps : \n",
    " 1. Normalize gene expression based on library size : `st.normalize(adata)`\n",
    " 2. Logarithmize gene expression : `st.log_transform(adata)`\n",
    " 3. Remove mitochondrial genes : `st.remove_mt_genes(adata)`\n",
    " 4. Filter out cells based on different metrics : `sc.filter_cells(adata)`\n",
    "  \n",
    "  Available options with their default value : \n",
    "  - min_n_features = 10 ; Minimum number of genes expressed\n",
    "  - min_pct_features = None ; Minimum percentage of genes expressed\n",
    "  - min_n_counts = None ; Minimum number of read count for one cell\n",
    "  - expr_cutoff = 1 ; If greater than expr_cutoff,the gene is considered 'expressed'\n",
    " 5. Filter out genes based on different metrics : `st.filter_features(adata)`\n",
    " \n",
    "  Available options with their default value : \n",
    "  - min_n_cells = 5 ; Minimum number of cells expressing one gene\n",
    "  - min_pct_cells = None ; Minimum percentage of cells expressing one gene\n",
    "  - min_n_counts = None ; Minimum number of read count for one gene\n",
    "  - expr_cutoff = 1 ; If greater than expr_cutoff,the gene is considered 'expressed'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.cal_qc(adata,assay='rna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.normalize(adata,method='lib_size')\n",
    "st.log_transform(adata)\n",
    "st.remove_mt_genes(adata)\n",
    "st.filter_cells(adata,min_n_features = 1000)\n",
    "st.filter_features(adata,min_n_cells = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to select the variable genes in our dataset by running `st.select_variable_genes(adata)`. The options of interest are : \n",
    " - loess_frac = 0.1\n",
    " - percentile = 95 ; Specify the percentile to select genes\n",
    " - save_fig = False\n",
    " - fig_name = 'std_vs_means.pdf'\n",
    " \n",
    "Check if the blue curve fits the points well. If not, please adjust the parameter loess_frac until the blue curve fits well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.select_variable_genes(adata, loess_frac=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction\n",
    "\n",
    "Several dimension reduction are available in STREAM : \n",
    " - Spectral embedding algorithm (`se`),\n",
    " - Modified locally linear embedding algorithm (`mlle`),\n",
    " - Uniform Manifold Approximation and Projection (`umap`) and \n",
    " - Principal component analysis (`pca`)\n",
    " \n",
    "By default STREAM use the Spectral embedding space to find trajectories. \n",
    " \n",
    "To run the dimension reduction run : `st.dimension_reduction(adata)`\n",
    " \n",
    "Options of interest : \n",
    " - n_neighbors = 50 ; The number of neighbor cells used for manifold learning\n",
    " - n_components = 3 ; Number of components to keep\n",
    " - method = 'se' ; Method used for dimension reduction\n",
    "\n",
    "To ensure reproductibility use eigen_solver = 'arpack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.dimension_reduction(adata,n_components=2, eigen_solver='arpack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards it's possible to visualize the reduction with `st.plot_dimension_reduction(adata)`\n",
    "\n",
    "With all the visualizing functions you have a `save_fig` parameters to allow you to save your figure in the workdir defined in `adata.uns['workdir']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_dimension_reduction(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory inference\n",
    "\n",
    "### Initial graph\n",
    "\n",
    "First we need to seed the intial principal graph with the function `st.seed_elastic_principal_graph`. Some of the available options are : \n",
    " - clustering = 'kmeans' ; clustering method used to infer the initial nodes, Choose from : 'ap','kmeans','sc'\n",
    " - n_clusters = 10 ; Number of clusters\n",
    " - n_neighbors = 50 ; The number of neighbor cells used for spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.seed_elastic_principal_graph(adata,n_clusters=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**\n",
    "\n",
    "Once the initial strucuture of the graph is computed we can visualize it with or without the cells : \n",
    " - `st.plot_branches(adata)`\n",
    " - `st.plot_dimension_reduction(adata,n_components=2,show_graph=True,show_text=False)`\n",
    " \n",
    "This functions can be used anytime to visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_dimension_reduction(adata,n_components=2,show_graph=True,show_text=False)\n",
    "st.plot_branches(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Graph**\n",
    "\n",
    "Now we can estimate the graph with : `st.elastic_principal_graph`\n",
    "\n",
    "`epg_alpha`, `epg_mu`, `epg_lambda` are the three most influential parameters for learning elastic principal graph : \n",
    "- `epg_alpha`: penalizes spurious branching events. **The larger, the fewer branches the function will learn.** (by default, `epg_alpha=0.02`)\n",
    "- `epg_mu`: penalizes the deviation from harmonic embedding, where harmonicity assumes that each node is the mean of its neighbor nodes. **The larger, the more edges the function will use to fit into points(cells)** (by default, `epg_mu=0.1`)\n",
    "- `epg_lambda`: penalizes the total length of edges. **The larger, the 'shorter' curves the function will use to fit into points(cells) and the fewer points(cells) the curves will reach.** (by default, `epg_lambda=0.02`)\n",
    "\n",
    "In case you have noisy points in your data you can use the `epg_trimmingradius` parameters, by default it is set to `Inf`, but a value of 0.1 can be a good starting point to get rid of this noisy points. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.elastic_principal_graph(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_dimension_reduction(adata,n_components=2,show_graph=True,show_text=False)\n",
    "st.plot_branches(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph optimization (optionnal)\n",
    "\n",
    "**Branching optimization**\n",
    "\n",
    "The most influential parameters are `epg_alpha`, `epg_mu`, `epg_lambda` and `epg_trimmingradius`. They have the same meanings as in `st.elastic_principal_graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.optimize_branching(adata,epg_alpha=0.02,epg_mu=0.1,epg_lambda=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_dimension_reduction(adata,n_components=2,show_graph=True,show_text=False)\n",
    "st.plot_branches(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prune branches**\n",
    "\n",
    "Prune the learnt elastic principal graph by filtering out 'trivial' branches with the function `st.prune_elastic_principal_graph`. \n",
    "Different method are available to prune the branches by specifying `epg_collapse_mode` parameter : \n",
    " - 'PointNumber': branches with less than `epg_collapse_par` points (points projected on the extreme points are not considered) are removed\n",
    " - 'PointNumber_Extrema', branches with less than `epg_collapse_par` (points projected on the extreme points are not considered) are removed\n",
    " - 'PointNumber_Leaves', branches with less than `epg_collapse_par` points (points projected on non-leaf extreme points are not considered) are removed\n",
    " - 'EdgesNumber', branches with less than `epg_collapse_par` edges are removed\n",
    " - 'EdgesLength', branches shorter than `epg_collapse_par` are removed \n",
    " \n",
    "To control the different method you can specify `epg_collapse_par` (by default `epg_collapse_par = 5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.prune_elastic_principal_graph(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shift branching**\n",
    "\n",
    "Move branching node to the area with higher density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.shift_branching(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extend leaf branch**\n",
    "\n",
    "Extend leaf branch to reach further cells by running `st.extend_elastic_principal_graph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.extend_elastic_principal_graph(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_dimension_reduction(adata,n_components=2,show_graph=True,show_text=False)\n",
    "st.plot_branches(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualization\n",
    "\n",
    "In some visualization you need to choose a root to your graph, It will not affect the results only the representation\n",
    "\n",
    "**Flat tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_flat_tree(adata,color=['label','branch_id_alias','S0_pseudotime'],\n",
    "                  dist_scale=0.5,show_graph=True,show_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subway plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_stream_sc(adata,root='S0',\n",
    "                  dist_scale=0.3,show_graph=True,show_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stream plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_stream(adata,root='S0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize genes**\n",
    "\n",
    "You can visualize gene expression along the different branches with two different function `st.plot_stream_sc` and `st.plot_stream`. To do so, you need to provide a list of genes (`[...]`) through the `color` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_stream_sc(adata,root='S0',color=['Gata1','Car2','Epx']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_stream(adata,root='S0',color=['Gata1','Car2','Epx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker gene detection\n",
    "\n",
    "**Marker gene detection part is a bit time-consuming, so please make sure the struture learned from previous steps is reasonble before running any maker gene detection steps**\n",
    "\n",
    "**Also it's not always necessary to execute all three marker gene detection parts. Running one of them might be adequate already.**\n",
    "\n",
    "### Detect marker genes for each leaf branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.detect_leaf_markers(adata,root='S0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['leaf_genes'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['leaf_genes'][('S0','S1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect transition gene for each branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.detect_transistion_markers(adata,root='S0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot_transition_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect differentially expressed genes between pairs of branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.detect_de_markers(adata,root='S0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['de_genes_greater'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['de_genes_less'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.write(adata,file_name='stream_result.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to dynverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_data_dynverse(adata,root = \"S0\", filename = 'stream_to_dynverse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stream]",
   "language": "python",
   "name": "conda-env-stream-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
